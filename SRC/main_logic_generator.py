"""
ä¸»é€»è¾‘çŸ¥è¯†å›¾è°±ç”Ÿæˆå™¨
åŠŸèƒ½ï¼šåŸºäºç« èŠ‚æ•°æ®æ„å»ºç« èŠ‚é—´å…³ç³»çš„ä¸»é€»è¾‘çŸ¥è¯†å›¾è°±
"""

import os
import json
import re
from typing import List, Dict, Any
from datetime import datetime
from openai import OpenAI

from .utils import config_manager, file_manager, logger, retry_on_failure

class MainLogicGenerator:
    """ä¸»é€»è¾‘çŸ¥è¯†å›¾è°±ç”Ÿæˆå™¨"""
    
    def __init__(self, workers: int = 8):
        """åˆå§‹åŒ–"""
        self.client = OpenAI(
            api_key="sk-pBUBTdSpfx0ppYf30rzzmbr60WiffKq52EQzx45r9rntGjli",
            base_url="https://www.dmxapi.cn/v1",
        )
        self.model = "DMXAPI-DeepSeek-V3"
        self.workers = workers
        
        print("ğŸ§  [ä¸»é€»è¾‘ç”Ÿæˆå™¨] åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“¡ ä½¿ç”¨æ¨¡å‹: {self.model}")
        print(f"ğŸš€ å¹¶å‘æ•°: {workers}")
    
    def generate_main_logic(self) -> Dict[str, Any]:
        """ç”Ÿæˆä¸»é€»è¾‘çŸ¥è¯†å›¾è°±"""
        print("\n" + "="*60)
        print("ğŸ§  å¼€å§‹ä¸»é€»è¾‘å›¾è°±ç”Ÿæˆ")
        print("="*60)
        
        # 1. åŠ è½½ç« èŠ‚æ•°æ®
        sections_data = self._load_sections_data()
        if not sections_data:
            print("âŒ æ— æ³•åŠ è½½ç« èŠ‚æ•°æ®")
            return {}
        
        # 2. ä½¿ç”¨CoTæ–¹æ³•åˆ†æç« èŠ‚å…³ç³»
        analysis_result = self._analyze_sections_with_cot(sections_data['sections'])
        if not analysis_result:
            print("âŒ ç« èŠ‚åˆ†æå¤±è´¥")
            return {}
        
        # 3. æ„å»ºä¸»é€»è¾‘çŸ¥è¯†å›¾è°±
        main_logic_kg = self._build_main_logic_kg(analysis_result)
        
        # 4. ä¿å­˜ç»“æœ
        self._save_main_logic_kg(main_logic_kg)
        
        print(f"âœ… ä¸»é€»è¾‘å›¾è°±ç”Ÿæˆå®Œæˆ")
        return main_logic_kg
    
    def _load_sections_data(self) -> Dict[str, Any]:
        """åŠ è½½ç« èŠ‚æ•°æ®"""
        print("ğŸ“‚ åŠ è½½ç« èŠ‚æ•°æ®...")
        
        try:
            sections_file = file_manager.get_path("sections", "document_sections.json")
            with open(sections_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            sections = data.get('sections', [])
            print(f"âœ… æˆåŠŸåŠ è½½ {len(sections)} ä¸ªç« èŠ‚")
            
            return data
            
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return {}
    
    def _analyze_sections_with_cot(self, sections: List[Dict]) -> Dict:
        """ä½¿ç”¨CoTæ–¹æ³•åˆ†æç« èŠ‚"""
        print(f"\nğŸ¤” ä½¿ç”¨CoTæ–¹æ³•åˆ†æç« èŠ‚å…³ç³»...")
        
        # å‡†å¤‡ç« èŠ‚æ‘˜è¦
        section_summaries = []
        for section in sections:
            content_preview = section['content'][:800] + "..." if len(section['content']) > 800 else section['content']
            section_summaries.append({
                'section_num': section['section_num'],
                'title': section['title'],
                'content_preview': content_preview,
                'content_length': len(section['content']),
                'word_count': len(section['content'].split())
            })
        
        # ä½¿ç”¨CoTè¿›è¡Œåˆ†æ
        analysis_result = self._call_deepseek_with_cot_analysis(section_summaries)
        
        return analysis_result
    
    @retry_on_failure(max_retries=3, delay=2.0)
    def _call_deepseek_with_cot_analysis(self, section_summaries: List[Dict]) -> Dict:
        """ä½¿ç”¨CoTæ–¹æ³•è°ƒç”¨DeepSeekè¿›è¡Œç« èŠ‚åˆ†æ"""
        
        cot_prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç”µè·¯è®¾è®¡æ•™è‚²ä¸“å®¶å’ŒçŸ¥è¯†å›¾è°±æ„å»ºä¸“å®¶ã€‚è¯·ä½¿ç”¨é€æ­¥æ€è€ƒçš„æ–¹æ³•åˆ†æä»¥ä¸‹ç”µè·¯æŠ€æœ¯ç« èŠ‚ï¼Œæ„å»ºä¸»é€»è¾‘çŸ¥è¯†å›¾è°±ã€‚

## ç¬¬ä¸€æ­¥ï¼šç« èŠ‚å†…å®¹ç†è§£
è¯·é€ä¸€åˆ†ææ¯ä¸ªç« èŠ‚çš„æ ¸å¿ƒå†…å®¹ï¼š

ç« èŠ‚ä¿¡æ¯ï¼š
{json.dumps(section_summaries, ensure_ascii=False, indent=2)}

### æ€è€ƒè¿‡ç¨‹ï¼š
1. æ¯ä¸ªç« èŠ‚çš„ä¸»è¦æŠ€æœ¯ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ
2. æ¯ä¸ªç« èŠ‚çš„éš¾åº¦å±‚çº§å¦‚ä½•ï¼Ÿ
3. æ¯ä¸ªç« èŠ‚çš„å­¦ä¹ ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ
4. æ¯ä¸ªç« èŠ‚éœ€è¦å“ªäº›å‰ç½®çŸ¥è¯†ï¼Ÿ

## ç¬¬äºŒæ­¥ï¼šçŸ¥è¯†å±‚æ¬¡åˆ†æ
è¯·å°†ç« èŠ‚æŒ‰ç…§ç”µè·¯å­¦ä¹ çš„é€»è¾‘å±‚æ¬¡è¿›è¡Œåˆ†ç±»ï¼š

### æ€è€ƒæ¡†æ¶ï¼š
- **åŸºç¡€ç†è®ºå±‚**ï¼šåŸºæœ¬æ¦‚å¿µã€åŸç†ã€æ•°å­¦åŸºç¡€
- **å™¨ä»¶æŠ€æœ¯å±‚**ï¼šå…·ä½“å™¨ä»¶ã€ç‰¹æ€§ã€æ¨¡å‹
- **ç”µè·¯è®¾è®¡å±‚**ï¼šç”µè·¯æ‹“æ‰‘ã€è®¾è®¡æ–¹æ³•ã€åˆ†ææŠ€å·§
- **ç³»ç»Ÿåº”ç”¨å±‚**ï¼šå®Œæ•´ç³»ç»Ÿã€å®é™…åº”ç”¨ã€å·¥ç¨‹å®è·µ
- **é«˜çº§ä¼˜åŒ–å±‚**ï¼šæ€§èƒ½ä¼˜åŒ–ã€å…ˆè¿›æŠ€æœ¯ã€åˆ›æ–°æ–¹æ³•

## ç¬¬ä¸‰æ­¥ï¼šä¾èµ–å…³ç³»è¯†åˆ«
è¯·åˆ†æç« èŠ‚é—´çš„é€»è¾‘ä¾èµ–å…³ç³»ï¼š

### å…³ç³»ç±»å‹å®šä¹‰ï¼š
- **depends_on**ï¼šå¿…é¡»å…ˆå­¦ä¹ Aæ‰èƒ½ç†è§£B
- **builds_on**ï¼šBæ˜¯Açš„è¿›é˜¶å’Œæ‰©å±•
- **applies_to**ï¼šAçš„æŠ€æœ¯åœ¨Bä¸­å¾—åˆ°åº”ç”¨
- **complements**ï¼šAå’ŒBç›¸äº’è¡¥å……
- **parallel_to**ï¼šAå’ŒBå¯ä»¥å¹¶è¡Œå­¦ä¹ 
- **cross_references**ï¼šAå’ŒBåœ¨æŸäº›æ¦‚å¿µä¸Šæœ‰äº¤é›†

## ç¬¬å››æ­¥ï¼šå­¦ä¹ è·¯å¾„è§„åˆ’
åŸºäºä¾èµ–å…³ç³»ï¼Œè®¾è®¡æœ€ä¼˜çš„å­¦ä¹ è·¯å¾„ã€‚

## ç¬¬äº”æ­¥ï¼šçŸ¥è¯†å›¾è°±æ„å»º
åŸºäºä»¥ä¸Šåˆ†æï¼Œæ„å»ºç»“æ„åŒ–çš„ä¸»é€»è¾‘çŸ¥è¯†å›¾è°±ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š

```json
{{
  "analysis_summary": {{
    "total_sections": {len(section_summaries)},
    "analysis_timestamp": "{datetime.now().isoformat()}",
    "complexity_distribution": {{
      "basic": 0,
      "intermediate": 0,
      "advanced": 0
    }},
    "main_themes": ["ä¸»é¢˜1", "ä¸»é¢˜2", "ä¸»é¢˜3"]
  }},
  "knowledge_hierarchy": {{
    "åŸºç¡€ç†è®ºå±‚": ["ç« èŠ‚å·1", "ç« èŠ‚å·2"],
    "å™¨ä»¶æŠ€æœ¯å±‚": ["ç« èŠ‚å·3", "ç« èŠ‚å·4"],
    "ç”µè·¯è®¾è®¡å±‚": ["ç« èŠ‚å·5", "ç« èŠ‚å·6"],
    "ç³»ç»Ÿåº”ç”¨å±‚": ["ç« èŠ‚å·7", "ç« èŠ‚å·8"],
    "é«˜çº§ä¼˜åŒ–å±‚": ["ç« èŠ‚å·9", "ç« èŠ‚å·10"]
  }},
  "main_knowledge_points": [
    {{
      "id": "main_1",
      "section_num": "ç« èŠ‚å·",
      "label": "ç« èŠ‚æ ‡é¢˜",
      "summary": "ç« èŠ‚æ ¸å¿ƒå†…å®¹æ¦‚è¿°",
      "difficulty": 3,
      "knowledge_layer": "ç”µè·¯è®¾è®¡å±‚",
      "key_concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"],
      "prerequisites": ["å‰ç½®ç« èŠ‚1", "å‰ç½®ç« èŠ‚2"],
      "learning_objectives": ["ç›®æ ‡1", "ç›®æ ‡2"]
    }}
  ],
  "section_relationships": [
    {{
      "source_id": "main_1",
      "target_id": "main_2",
      "relationship": "depends_on",
      "description": "è¯¦ç»†æè¿°ä¾èµ–å…³ç³»",
      "weight": 0.8,
      "reasoning": "æ¨ç†è¿‡ç¨‹"
    }}
  ],
  "learning_paths": [
    {{
      "path_name": "åŸºç¡€åˆ°åº”ç”¨è·¯å¾„",
      "description": "ä»åŸºç¡€ç†è®ºåˆ°å®é™…åº”ç”¨çš„å­¦ä¹ è·¯å¾„",
      "sections_sequence": ["1.1", "1.2", "2.1", "3.1"],
      "estimated_duration": "4å‘¨",
      "difficulty_progression": "é€’å¢"
    }}
  ]
}}
```

è¦æ±‚ï¼š
1. æ¯ä¸ªç« èŠ‚éƒ½è¦åˆ†æåˆ°
2. å…³ç³»è¦åŸºäºå®é™…çš„æŠ€æœ¯é€»è¾‘
3. å­¦ä¹ è·¯å¾„è¦åˆç†å¯è¡Œ
4. JSONæ ¼å¼è¦ä¸¥æ ¼æ­£ç¡®

å¼€å§‹åˆ†æï¼š"""
        
        try:
            response = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç”µè·¯è®¾è®¡æ•™è‚²ä¸“å®¶å’ŒçŸ¥è¯†å›¾è°±æ„å»ºä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æç« èŠ‚é—´çš„é€»è¾‘å…³ç³»ï¼Œæ„å»ºåˆç†çš„å­¦ä¹ è·¯å¾„ã€‚"},
                    {"role": "user", "content": cot_prompt}
                ],
                model=self.model,
                temperature=0.1,
                max_tokens=8000
            )
            
            result_content = response.choices[0].message.content.strip()
            
            # è§£æJSONç»“æœ
            json_str = self._clean_json_response(result_content)
            analysis_data = json.loads(json_str)
            
            return analysis_data
            
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {result_content[:500]}...")
            return {}
            
        except Exception as e:
            print(f"AIåˆ†æå¤±è´¥: {e}")
            return {}
    
    def _clean_json_response(self, content: str) -> str:
        """æ¸…ç†JSONå“åº”"""
        # ç§»é™¤markdownä»£ç å—æ ‡è®°
        content = re.sub(r'```json\s*', '', content)
        content = re.sub(r'```\s*$', '', content)
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        content = content.strip()
        
        # å°è¯•æ‰¾åˆ°JSONå¯¹è±¡çš„å¼€å§‹å’Œç»“æŸ
        start_idx = content.find('{')
        end_idx = content.rfind('}')
        
        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            content = content[start_idx:end_idx+1]
        
        return content
    
    def _build_main_logic_kg(self, analysis_result: Dict) -> Dict[str, Any]:
        """æ„å»ºä¸»é€»è¾‘çŸ¥è¯†å›¾è°±"""
        print("ğŸ”¨ æ„å»ºä¸»é€»è¾‘çŸ¥è¯†å›¾è°±...")
        
        main_logic_kg = {
            'title': 'ä¸»é€»è¾‘çŸ¥è¯†å›¾è°±',
            'timestamp': datetime.now().isoformat(),
            'nodes': analysis_result.get('main_knowledge_points', []),
            'edges': analysis_result.get('section_relationships', []),
            'knowledge_hierarchy': analysis_result.get('knowledge_hierarchy', {}),
            'learning_paths': analysis_result.get('learning_paths', []),
            'metadata': {
                'generator': 'MainLogicGenerator',
                'analysis_summary': analysis_result.get('analysis_summary', {}),
                'total_nodes': len(analysis_result.get('main_knowledge_points', [])),
                'total_edges': len(analysis_result.get('section_relationships', []))
            }
        }
        
        print(f"âœ… ä¸»é€»è¾‘çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ")
        print(f"   - èŠ‚ç‚¹æ•°: {len(main_logic_kg['nodes'])}")
        print(f"   - è¾¹æ•°: {len(main_logic_kg['edges'])}")
        print(f"   - å­¦ä¹ è·¯å¾„: {len(main_logic_kg['learning_paths'])}")
        
        return main_logic_kg
    
    def _save_main_logic_kg(self, main_logic_kg: Dict[str, Any]):
        """ä¿å­˜ä¸»é€»è¾‘çŸ¥è¯†å›¾è°±"""
        print("ğŸ’¾ ä¿å­˜ä¸»é€»è¾‘çŸ¥è¯†å›¾è°±...")
        
        # ä¿å­˜å®Œæ•´çš„ä¸»é€»è¾‘å›¾è°±
        file_manager.save_json(main_logic_kg, "main_logic", "main_logic_kg.json")
        
        # ä¿å­˜èŠ‚ç‚¹å’Œè¾¹çš„å•ç‹¬æ–‡ä»¶
        file_manager.save_json(main_logic_kg['nodes'], "main_logic", "main_logic_nodes.json")
        file_manager.save_json(main_logic_kg['edges'], "main_logic", "main_logic_edges.json")
        
        # ä¿å­˜å­¦ä¹ è·¯å¾„
        file_manager.save_json(main_logic_kg['learning_paths'], "main_logic", "learning_paths.json")
        
        print(f"âœ… ä¸»é€»è¾‘çŸ¥è¯†å›¾è°±ä¿å­˜å®Œæˆ")

def main():
    """æµ‹è¯•å‡½æ•°"""
    generator = MainLogicGenerator(workers=8)
    
    # ç”Ÿæˆä¸»é€»è¾‘å›¾è°±
    result = generator.generate_main_logic()
    
    if result:
        print(f"ç”ŸæˆæˆåŠŸ: {len(result.get('nodes', []))} ä¸ªèŠ‚ç‚¹")
    else:
        print("ç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    main()
