"""
æ–‡æ¡£åˆ†å‰²å™¨ - åŸºäºç›®å½•åŒ¹é…æ­£æ–‡è¿›è¡Œå†…å®¹åˆ†å‰²
åŠŸèƒ½ï¼šæ™ºèƒ½è¯†åˆ«ç›®å½•ç»“æ„ï¼Œç²¾ç¡®åˆ†å‰²ç« èŠ‚å†…å®¹
"""

import os
import re
import json
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime
from dataclasses import dataclass
from pathlib import Path
from openai import OpenAI
from .utils import config_manager, file_manager, logger, retry_on_failure

@dataclass
class TOCTitle:
    """ç›®å½•æ ‡é¢˜"""
    section_num: str
    title: str
    page_num: str
    line_num: int

@dataclass
class ContentTitle:
    """æ­£æ–‡æ ‡é¢˜"""
    line_num: int
    section_num: str
    title: str
    full_line: str
    title_type: str  # markdown, numbered, chapter

class DocumentSplitter:
    """æ–‡æ¡£åˆ†å‰²å™¨ - åŸºäºç›®å½•åŒ¹é…çš„æ™ºèƒ½åˆ†å‰²"""

    def __init__(self, workers: int = 8):
        """åˆå§‹åŒ–"""
        self.client = OpenAI(
            api_key="sk-pBUBTdSpfx0ppYf30rzzmbr60WiffKq52EQzx45r9rntGjli",
            base_url="https://www.dmxapi.cn/v1",
        )
        self.model = "DMXAPI-DeepSeek-V3"
        self.workers = workers

        # åˆ†å‰²å™¨çŠ¶æ€
        self.toc_titles = []
        self.content_titles = []
        self.toc_end_line = 0
        self.matched_sections = []

        print("ğŸ“š [æ–‡æ¡£åˆ†å‰²å™¨] åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“¡ ä½¿ç”¨æ¨¡å‹: {self.model}")
        print(f"ğŸš€ å¹¶å‘æ•°: {workers}")
    
    def split_document(self, input_file: str) -> Dict[str, Any]:
        """åˆ†å‰²æ–‡æ¡£ - åŸºäºç›®å½•åŒ¹é…çš„æ™ºèƒ½åˆ†å‰²"""
        print("\n" + "="*60)
        print("ğŸ“š å¼€å§‹æ™ºèƒ½æ–‡æ¡£åˆ†å‰²")
        print("="*60)
        
        try:
            # 1. è¯»å–è¾“å…¥æ–‡ä»¶
            lines = self._read_input_file(input_file)
            if not lines:
                logger.error("æ— æ³•è¯»å–è¾“å…¥æ–‡ä»¶")
                return {}
            
            # 2. æå–ç›®å½•æ ‡é¢˜
            toc_titles, toc_end_line = self._extract_toc_titles(lines)
            if not toc_titles:
                logger.warning("æœªæ‰¾åˆ°ç›®å½•æ ‡é¢˜ï¼Œä½¿ç”¨ç®€å•åˆ†å‰²")
                return self._simple_split_fallback(lines)
            
            # 3. æå–æ­£æ–‡æ ‡é¢˜
            content_titles = self._extract_content_titles(lines, toc_end_line)
            if not content_titles:
                logger.warning("æœªæ‰¾åˆ°æ­£æ–‡æ ‡é¢˜ï¼Œä½¿ç”¨ç®€å•åˆ†å‰²")
                return self._simple_split_fallback(lines)
            
            # 4. AIæ™ºèƒ½åŒ¹é…ç›®å½•å’Œæ­£æ–‡
            matched_sections = self._match_toc_with_content()
            if not matched_sections:
                logger.warning("ç›®å½•å’Œæ­£æ–‡åŒ¹é…å¤±è´¥ï¼Œä½¿ç”¨ç®€å•åˆ†å‰²")
                return self._simple_split_fallback(lines)
            
            # 5. æ ¹æ®åŒ¹é…ç»“æœåˆ†å‰²å†…å®¹
            sections = self._split_content_by_sections(lines)
            if not sections:
                logger.error("å†…å®¹åˆ†å‰²å¤±è´¥")
                return {}
            
            # 6. æ„å»ºæœ€ç»ˆæ•°æ®ç»“æ„
            sections_data = self._build_sections_data(sections)
            
            # 7. ä¿å­˜ç»“æœ
            self._save_sections(sections_data)
            
            print(f"âœ… æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œå…±åˆ†å‰²å‡º {len(sections)} ä¸ªç« èŠ‚")
            return sections_data
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£åˆ†å‰²å¤±è´¥: {e}")
            return {}
    
    def _read_input_file(self, input_file: str) -> List[str]:
        """è¯»å–è¾“å…¥æ–‡ä»¶å¹¶æŒ‰è¡Œåˆ†å‰²"""
        try:
            input_path = Path(input_file)
            if not input_path.exists():
                # å°è¯•åœ¨data/inputç›®å½•ä¸­æŸ¥æ‰¾
                input_path = file_manager.get_path("input", input_file)
            
            with open(input_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            print(f"ğŸ“– æˆåŠŸè¯»å–æ–‡ä»¶: {input_path}")
            print(f"ğŸ“Š æ€»è¡Œæ•°: {len(lines):,}")
            return lines
            
        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def _extract_toc_titles(self, lines: List[str]) -> Tuple[List[TOCTitle], int]:
        """æå–ç›®å½•æ ‡é¢˜ï¼Œè¿”å›ç›®å½•æ ‡é¢˜åˆ—è¡¨å’Œç›®å½•ç»“æŸè¡Œå·"""
        print("ğŸ“š [æ­¥éª¤1] æå–ç›®å½•æ ‡é¢˜...")
        
        toc_titles = []
        in_toc_section = False
        toc_end_line = 0
        
        # ç›®å½•æ ‡è¯†ç¬¦
        toc_indicators = ['ç›®å½•', 'ç›® å½•', 'Contents', 'TOC', 'å†…å®¹ç›®å½•', 'ç« èŠ‚ç›®å½•']
        
        for line_num, line in enumerate(lines):
            line_clean = line.strip()
            
            if not line_clean:
                continue
            
            # æ£€æŸ¥æ˜¯å¦è¿›å…¥ç›®å½•éƒ¨åˆ†
            if not in_toc_section:
                if any(indicator in line_clean for indicator in toc_indicators):
                    in_toc_section = True
                    print(f"ğŸ“ å‘ç°ç›®å½•å¼€å§‹: ç¬¬{line_num+1}è¡Œ - {line_clean}")
                    continue
            
            # å¦‚æœåœ¨ç›®å½•éƒ¨åˆ†ï¼Œå°è¯•æå–æ ‡é¢˜
            if in_toc_section:
                # åŒ¹é…ç›®å½•æ ¼å¼
                patterns = [
                    r'^(\d+\.?\d*\.?\d*)\s+(.+?)\s*\.+\s*(\d+)$',  # 1.1 æ ‡é¢˜...... é¡µç 
                    r'^(\d+\.?\d*\.?\d*)\s+(.+?)\s+(\d+)$',  # 1.1 æ ‡é¢˜ é¡µç 
                    r'^(\d+\.?\d*\.?\d*)\s+(.+)$',  # 1.1 æ ‡é¢˜ (æ— é¡µç )
                    r'^ç¬¬(\d+)[ç« èŠ‚]\s+(.+?)\s*\.+\s*(\d+)$',  # ç¬¬1ç«  æ ‡é¢˜...... é¡µç 
                    r'^ç¬¬(\d+)[ç« èŠ‚]\s+(.+?)\s+(\d+)$',  # ç¬¬1ç«  æ ‡é¢˜ é¡µç 
                    r'^ç¬¬(\d+)[ç« èŠ‚]\s+(.+)$',  # ç¬¬1ç«  æ ‡é¢˜
                ]
                
                matched = False
                for pattern in patterns:
                    match = re.match(pattern, line_clean)
                    if match:
                        if pattern.startswith('^ç¬¬'):
                            section_num = match.group(1)
                            title = match.group(2).strip()
                            page_num = match.group(3) if len(match.groups()) >= 3 else ""
                        else:
                            section_num = match.group(1)
                            title = match.group(2).strip()
                            page_num = match.group(3) if len(match.groups()) >= 3 else ""
                        
                        # æ¸…ç†æ ‡é¢˜
                        title = re.sub(r'\.+$', '', title).strip()
                        
                        if title and len(title) > 1:  # æœ‰æ•ˆæ ‡é¢˜
                            toc_title = TOCTitle(
                                section_num=section_num,
                                title=title,
                                page_num=page_num,
                                line_num=line_num + 1
                            )
                            toc_titles.append(toc_title)
                            matched = True
                            break
                
                # æ£€æŸ¥æ˜¯å¦ç›®å½•ç»“æŸ
                if not matched and len(toc_titles) > 3:
                    # è¿ç»­å‡ è¡Œéƒ½ä¸åŒ¹é…ï¼Œå¯èƒ½ç›®å½•ç»“æŸäº†
                    if (len(line_clean) > 50 or  # é•¿æ–‡æœ¬
                        re.match(r'^ç¬¬?\d+[ç« èŠ‚]', line_clean) or  # ç« èŠ‚å¼€å§‹
                        re.match(r'^\d+\.\d+', line_clean) or  # å­ç« èŠ‚å¼€å§‹
                        re.match(r'^#+\s', line_clean)):  # markdownæ ‡é¢˜
                        toc_end_line = line_num
                        print(f"ğŸ“ ç›®å½•ç»“æŸ: ç¬¬{line_num+1}è¡Œ")
                        break
        
        # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„ç»“æŸæ ‡è®°ï¼Œä¼°ç®—ç›®å½•ç»“æŸä½ç½®
        if toc_end_line == 0 and toc_titles:
            toc_end_line = toc_titles[-1].line_num + 5  # ç›®å½•æœ€åä¸€è¡Œå5è¡Œ
        
        print(f"ğŸ“Š æå–ç›®å½•æ ‡é¢˜: {len(toc_titles)} ä¸ª")
        print(f"ğŸ“Š ç›®å½•ç»“æŸè¡Œ: {toc_end_line}")
        
        # æ˜¾ç¤ºæå–çš„ç›®å½•æ ‡é¢˜
        if toc_titles:
            print("\nğŸ“‹ ç›®å½•æ ‡é¢˜:")
            for i, title in enumerate(toc_titles):
                print(f"  {i+1:2d}. {title.section_num} - {title.title}")
        
        self.toc_titles = toc_titles
        self.toc_end_line = toc_end_line
        return toc_titles, toc_end_line
    
    def _extract_content_titles(self, lines: List[str], start_line: int) -> List[ContentTitle]:
        """æå–æ­£æ–‡æ ‡é¢˜ï¼ˆä»ç›®å½•ç»“æŸåå¼€å§‹ï¼‰"""
        print(f"\nğŸ” [æ­¥éª¤2] æå–æ­£æ–‡æ ‡é¢˜ (ä»ç¬¬{start_line+1}è¡Œå¼€å§‹)...")
        
        content_titles = []
        
        for line_num in range(start_line, len(lines)):
            line_clean = lines[line_num].strip()
            
            if not line_clean or len(line_clean) < 3:
                continue
            
            # æå–å„ç§æ ¼å¼çš„æ ‡é¢˜
            title_found = False
            
            # 1. Markdownæ ¼å¼æ ‡é¢˜ (# ## ### ####)
            markdown_match = re.match(r'^(#+)\s+(.+)$', line_clean)
            if markdown_match:
                hash_count = len(markdown_match.group(1))
                title = markdown_match.group(2).strip()
                
                # å°è¯•ä»titleä¸­æå–ç« èŠ‚å·
                section_num = ""
                section_match = re.match(r'^(\d+\.?\d*\.?\d*)\s+(.+)$', title)
                if section_match:
                    section_num = section_match.group(1)
                    title = section_match.group(2).strip()
                else:
                    section_num = f"h{hash_count}"  # ç”¨hashæ•°é‡ä½œä¸ºç¼–å·
                
                content_title = ContentTitle(
                    line_num=line_num + 1,
                    section_num=section_num,
                    title=title,
                    full_line=line_clean,
                    title_type="markdown"
                )
                content_titles.append(content_title)
                title_found = True
            
            # 2. æ•°å­—ç¼–å·æ ‡é¢˜ (1. 1.1 1.1.1 ç­‰)
            if not title_found:
                numbered_patterns = [
                    r'^(\d+)\.\s+(.+)$',  # 1. æ ‡é¢˜
                    r'^(\d+\.\d+)\s+(.+)$',  # 1.1 æ ‡é¢˜
                    r'^(\d+\.\d+\.\d+)\s+(.+)$',  # 1.1.1 æ ‡é¢˜
                    r'^(\d+\.\d+\.\d+\.\d+)\s+(.+)$',  # 1.1.1.1 æ ‡é¢˜
                ]
                
                for pattern in numbered_patterns:
                    match = re.match(pattern, line_clean)
                    if match:
                        section_num = match.group(1)
                        title = match.group(2).strip()
                        
                        content_title = ContentTitle(
                            line_num=line_num + 1,
                            section_num=section_num,
                            title=title,
                            full_line=line_clean,
                            title_type="numbered"
                        )
                        content_titles.append(content_title)
                        title_found = True
                        break
            
            # 3. ç« èŠ‚æ ‡é¢˜ (ç¬¬1ç«  ç¬¬2èŠ‚ç­‰)
            if not title_found:
                chapter_patterns = [
                    r'^ç¬¬(\d+)[ç« èŠ‚]\s+(.+)$',  # ç¬¬1ç«  æ ‡é¢˜
                    r'^ç¬¬(\d+)[ç« èŠ‚]\s*(.*)$',  # ç¬¬1ç«  (å¯èƒ½æ²¡æœ‰æ ‡é¢˜)
                ]
                
                for pattern in chapter_patterns:
                    match = re.match(pattern, line_clean)
                    if match:
                        section_num = match.group(1)
                        title = match.group(2).strip() if match.group(2) else f"ç¬¬{section_num}ç« "
                        
                        content_title = ContentTitle(
                            line_num=line_num + 1,
                            section_num=section_num,
                            title=title,
                            full_line=line_clean,
                            title_type="chapter"
                        )
                        content_titles.append(content_title)
                        title_found = True
                        break
        
        print(f"ğŸ“Š æå–æ­£æ–‡æ ‡é¢˜: {len(content_titles)} ä¸ª")
        
        # æ˜¾ç¤ºæå–çš„æ­£æ–‡æ ‡é¢˜
        if content_titles:
            print("\nğŸ“‹ æ­£æ–‡æ ‡é¢˜:")
            for i, title in enumerate(content_titles[:20]):  # æ˜¾ç¤ºå‰20ä¸ª
                print(f"  {i+1:2d}. ç¬¬{title.line_num:4d}è¡Œ [{title.title_type}]: {title.section_num} - {title.title}")
            if len(content_titles) > 20:
                print(f"  ... è¿˜æœ‰ {len(content_titles) - 20} ä¸ªæ ‡é¢˜")
        
        self.content_titles = content_titles
        return content_titles

    @retry_on_failure(max_retries=3, delay=2.0)
    def _match_toc_with_content(self) -> List[Dict]:
        """ä½¿ç”¨å¤§æ¨¡å‹åŒ¹é…ç›®å½•å’Œæ­£æ–‡æ ‡é¢˜"""
        print(f"\nğŸ¤– [æ­¥éª¤3] ä½¿ç”¨å¤§æ¨¡å‹åŒ¹é…ç›®å½•å’Œæ­£æ–‡æ ‡é¢˜...")

        if not self.toc_titles or not self.content_titles:
            print("âŒ ç›®å½•æ ‡é¢˜æˆ–æ­£æ–‡æ ‡é¢˜ä¸ºç©º")
            return []

        try:
            # å‡†å¤‡æ•°æ®
            toc_data = [
                {
                    'section_num': toc.section_num,
                    'title': toc.title,
                    'page_num': toc.page_num
                }
                for toc in self.toc_titles
            ]

            content_data = [
                {
                    'line_num': content.line_num,
                    'section_num': content.section_num,
                    'title': content.title,
                    'full_line': content.full_line,
                    'title_type': content.title_type
                }
                for content in self.content_titles
            ]

            # è°ƒç”¨å¤§æ¨¡å‹åŒ¹é…
            matches = self._call_llm_for_matching(toc_data, content_data)

            # å¤„ç†åŒ¹é…ç»“æœ
            matched_sections = []
            if matches:
                for match in matches:
                    try:
                        matched_sections.append({
                            'toc_section_num': match['toc_section_num'],
                            'toc_title': match['toc_title'],
                            'content_line_num': match['content_line_num'],
                            'content_section_num': match['content_section_num'],
                            'content_title': match['content_title'],
                            'confidence': match.get('confidence', 0.0)
                        })
                    except Exception as e:
                        print(f"âš ï¸ è§£æåŒ¹é…ç»“æœé”™è¯¯: {e}")
                        continue

            # æŒ‰è¡Œå·æ’åº
            matched_sections.sort(key=lambda x: x['content_line_num'])

            print(f"ğŸ“Š åŒ¹é…å®Œæˆ: {len(matched_sections)} ä¸ªåŒ¹é…")

            # æ˜¾ç¤ºåŒ¹é…ç»“æœ
            if matched_sections:
                print("\nğŸ¯ åŒ¹é…ç»“æœ:")
                for i, match in enumerate(matched_sections):
                    print(f"  {i+1:2d}. ç›®å½•: {match['toc_section_num']} {match['toc_title']}")
                    print(f"      æ­£æ–‡: ç¬¬{match['content_line_num']:4d}è¡Œ {match['content_section_num']} {match['content_title']}")
                    print(f"      ç½®ä¿¡åº¦: {match['confidence']:.2f}")

            self.matched_sections = matched_sections
            return matched_sections

        except Exception as e:
            logger.error(f"åŒ¹é…å¤±è´¥: {e}")
            return []

    def _call_llm_for_matching(self, toc_data: List[Dict], content_data: List[Dict]) -> Optional[List[Dict]]:
        """è°ƒç”¨å¤§æ¨¡å‹è¿›è¡ŒåŒ¹é…"""
        try:
            # ç”±äºæ•°æ®é‡å¯èƒ½å¾ˆå¤§ï¼Œåˆ†æ‰¹å¤„ç†
            batch_size = 30
            all_matches = []

            for i in range(0, len(toc_data), batch_size):
                toc_batch = toc_data[i:i+batch_size]

                prompt = f"""
è¯·å°†ä»¥ä¸‹ç›®å½•æ ‡é¢˜ä¸æ­£æ–‡æ ‡é¢˜è¿›è¡ŒåŒ¹é…ã€‚

ç›®å½•æ ‡é¢˜:
{json.dumps(toc_batch, ensure_ascii=False, indent=2)}

æ­£æ–‡æ ‡é¢˜:
{json.dumps(content_data, ensure_ascii=False, indent=2)}

åŒ¹é…è¦æ±‚:
1. æ¯ä¸ªç›®å½•æ ‡é¢˜åŒ¹é…ä¸€ä¸ªæœ€ç›¸ä¼¼çš„æ­£æ–‡æ ‡é¢˜
2. ä¼˜å…ˆè€ƒè™‘ç« èŠ‚å·çš„åŒ¹é…ï¼Œå…¶æ¬¡è€ƒè™‘æ ‡é¢˜å†…å®¹çš„ç›¸ä¼¼æ€§
3. å…è®¸æ ¼å¼å·®å¼‚ï¼ˆå¦‚ "1.1" ä¸ "## 1.1"ï¼‰
4. å¦‚æœæ ‡é¢˜å†…å®¹é«˜åº¦ç›¸ä¼¼ï¼Œå³ä½¿ç« èŠ‚å·ä¸åŒä¹Ÿå¯ä»¥åŒ¹é…
5. ç»™å‡ºåŒ¹é…ç½®ä¿¡åº¦(0-1)ï¼Œç½®ä¿¡åº¦ä½äº0.5çš„å¯ä»¥ä¸åŒ¹é…

è¯·è¿”å›JSONæ ¼å¼:
{{
  "matches": [
    {{
      "toc_section_num": "ç›®å½•ç« èŠ‚å·",
      "toc_title": "ç›®å½•æ ‡é¢˜",
      "content_line_num": æ­£æ–‡è¡Œå·,
      "content_section_num": "æ­£æ–‡ç« èŠ‚å·",
      "content_title": "æ­£æ–‡æ ‡é¢˜",
      "confidence": 0.95
    }}
  ]
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

                print(f"[è°ƒè¯•] è°ƒç”¨APIåŒ¹é…ç¬¬{i//batch_size + 1}æ‰¹...")
                response = self.client.chat.completions.create(
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©æ‰‹ã€‚è¯·ä»”ç»†åˆ†æç›®å½•å’Œæ­£æ–‡æ ‡é¢˜çš„å¯¹åº”å…³ç³»ï¼Œä¸¥æ ¼æŒ‰JSONæ ¼å¼è¿”å›ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    model=self.model,
                    temperature=0.1,
                    max_tokens=8000
                )

                content = response.choices[0].message.content.strip()

                # è§£æJSON - ä½¿ç”¨æ”¹è¿›çš„æ¸…ç†æ–¹æ³•
                json_str = self._clean_json_response(content)
                data = json.loads(json_str)
                matches = data.get("matches", [])
                all_matches.extend(matches)
                print(f"[æˆåŠŸ] ç¬¬{i//batch_size + 1}æ‰¹åŒ¹é…: {len(matches)} ä¸ª")

            return all_matches

        except Exception as e:
            print(f"[é”™è¯¯] å¤§æ¨¡å‹åŒ¹é…å¤±è´¥: {e}")
            return None

    def _clean_json_response(self, content: str) -> str:
        """æ¸…ç†JSONå“åº”"""
        # ç§»é™¤markdownä»£ç å—æ ‡è®°
        content = re.sub(r'```json\s*', '', content)
        content = re.sub(r'```\s*$', '', content)

        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        content = content.strip()

        # å°è¯•æ‰¾åˆ°JSONå¯¹è±¡çš„å¼€å§‹å’Œç»“æŸ
        start_idx = content.find('{')
        end_idx = content.rfind('}')

        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            content = content[start_idx:end_idx+1]

        return content

    def _split_content_by_sections(self, lines: List[str]) -> List[Dict]:
        """æ ¹æ®åŒ¹é…ç»“æœåˆ†å‰²å†…å®¹"""
        print(f"\nâœ‚ï¸ [æ­¥éª¤4] æ ¹æ®åŒ¹é…ç»“æœåˆ†å‰²å†…å®¹...")

        if not self.matched_sections:
            print("âŒ æ²¡æœ‰åŒ¹é…ç»“æœ")
            return []

        sections = []

        for i, match in enumerate(self.matched_sections):
            start_line = match['content_line_num'] - 1  # è½¬ä¸º0ç´¢å¼•

            # ç¡®å®šç»“æŸè¡Œï¼ˆä¸‹ä¸€ä¸ªç« èŠ‚çš„å¼€å§‹è¡Œï¼‰
            if i < len(self.matched_sections) - 1:
                end_line = self.matched_sections[i + 1]['content_line_num'] - 1
            else:
                end_line = len(lines)

            # æå–å†…å®¹
            content_lines = []
            for line_idx in range(start_line, end_line):
                if line_idx < len(lines):
                    line = lines[line_idx].strip()
                    if line:  # åªä¿ç•™éç©ºè¡Œ
                        content_lines.append(line)

            # åˆ›å»ºç« èŠ‚æ•°æ®
            section = {
                'section_num': match['toc_section_num'],
                'title': match['toc_title'],
                'start_line': start_line + 1,
                'end_line': end_line,
                'content': '\n'.join(content_lines)
            }

            sections.append(section)

        print(f"ğŸ“Š åˆ†å‰²å®Œæˆ: {len(sections)} ä¸ªç« èŠ‚")

        # æ˜¾ç¤ºåˆ†å‰²ç»“æœ
        if sections:
            print("\nğŸ“‹ ç« èŠ‚åˆ†å‰²:")
            for i, section in enumerate(sections):
                content_preview = section['content'][:100] + "..." if len(section['content']) > 100 else section['content']
                print(f"  {i+1:2d}. {section['section_num']} {section['title']}")
                print(f"      è¡Œæ•°: {section['start_line']}-{section['end_line']}")
                print(f"      å†…å®¹: {content_preview}")
                print()

        return sections

    def _build_sections_data(self, sections: List[Dict]) -> Dict[str, Any]:
        """æ„å»ºæœ€ç»ˆæ•°æ®ç»“æ„"""
        return {
            'title': 'æ™ºèƒ½åˆ†å‰²æ–‡æ¡£',
            'timestamp': datetime.now().isoformat(),
            'total_sections': len(sections),
            'sections': sections,
            'metadata': {
                'splitter_method': 'toc_content_matching',
                'toc_titles_count': len(self.toc_titles),
                'content_titles_count': len(self.content_titles),
                'matched_count': len(self.matched_sections),
                'toc_end_line': self.toc_end_line
            }
        }

    def _simple_split_fallback(self, lines: List[str]) -> Dict[str, Any]:
        """ç®€å•åˆ†å‰²é™çº§æ–¹æ¡ˆ"""
        print("ğŸ”§ ä½¿ç”¨ç®€å•åˆ†å‰²ä½œä¸ºé™çº§æ–¹æ¡ˆ...")

        sections = []
        current_section = None
        current_content = []
        section_count = 1

        for line_num, line in enumerate(lines):
            line_clean = line.strip()

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜è¡Œ
            if re.match(r'^#+\s+', line_clean) or re.match(r'^\d+\.?\d*\.?\d*\s+', line_clean):
                # ä¿å­˜å‰ä¸€ä¸ªç« èŠ‚
                if current_section:
                    current_section['content'] = '\n'.join(current_content).strip()
                    if current_section['content']:
                        sections.append(current_section)

                # å¼€å§‹æ–°ç« èŠ‚
                title = re.sub(r'^#+\s*', '', line_clean)
                title = re.sub(r'^\d+\.?\d*\.?\d*\s*', '', title)

                current_section = {
                    'section_num': str(section_count),
                    'title': title or f'ç« èŠ‚{section_count}',
                    'start_line': line_num + 1,
                    'end_line': line_num + 1,
                    'content': ''
                }
                current_content = []
                section_count += 1
            else:
                if current_section and line_clean:
                    current_content.append(line_clean)

        # ä¿å­˜æœ€åä¸€ä¸ªç« èŠ‚
        if current_section:
            current_section['content'] = '\n'.join(current_content).strip()
            if current_section['content']:
                sections.append(current_section)

        return self._build_sections_data(sections)

    def _save_sections(self, sections_data: Dict[str, Any]):
        """ä¿å­˜åˆ†å‰²ç»“æœ"""
        print("ğŸ’¾ ä¿å­˜åˆ†å‰²ç»“æœ...")

        # ä¿å­˜å®Œæ•´çš„ç« èŠ‚æ•°æ®
        file_manager.save_json(sections_data, "sections", "document_sections.json")

        # ä¿å­˜æ¯ä¸ªç« èŠ‚çš„å•ç‹¬æ–‡ä»¶
        for i, section in enumerate(sections_data.get('sections', [])):
            section_filename = f"section_{section['section_num'].replace('.', '_')}.json"
            file_manager.save_json(section, "sections", section_filename)

        # ç”Ÿæˆç« èŠ‚æ‘˜è¦
        summary = {
            'title': sections_data.get('title', 'Unknown'),
            'total_sections': len(sections_data.get('sections', [])),
            'sections_summary': [
                {
                    'section_num': s['section_num'],
                    'title': s['title'],
                    'content_length': len(s['content'])
                }
                for s in sections_data.get('sections', [])
            ]
        }

        file_manager.save_json(summary, "sections", "sections_summary.json")

        print(f"âœ… ç« èŠ‚æ•°æ®ä¿å­˜å®Œæˆ")

def main():
    """æµ‹è¯•å‡½æ•°"""
    splitter = DocumentSplitter(workers=8)

    # æµ‹è¯•åˆ†å‰²
    result = splitter.split_document("data/input/06_12CMOSæ¨¡æ‹ŸIPçº¿æ€§é›†æˆç”µè·¯_å´é‡‘ (1).md")

    if result:
        print(f"åˆ†å‰²æˆåŠŸ: {len(result.get('sections', []))} ä¸ªç« èŠ‚")
    else:
        print("åˆ†å‰²å¤±è´¥")

if __name__ == "__main__":
    main()
