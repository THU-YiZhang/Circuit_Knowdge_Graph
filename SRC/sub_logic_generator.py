"""
å­é€»è¾‘å›¾è°±ç”Ÿæˆå™¨ - å¹¶è¡Œç‰ˆæœ¬
åŠŸèƒ½ï¼šåŸºäºç« èŠ‚å†…å®¹æ„å»ºä¸‰å…ƒç»„çŸ¥è¯†å›¾è°±ï¼Œæå–åŸºç¡€æ¦‚å¿µ-æ ¸å¿ƒæŠ€æœ¯-ç”µè·¯åº”ç”¨çš„å±‚æ¬¡ç»“æ„
"""

import os
import json
import re
import time
from typing import List, Dict, Any, Tuple
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from openai import OpenAI

from .utils import config_manager, file_manager, logger, retry_on_failure, ProgressTracker

class SubLogicGenerator:
    """å­é€»è¾‘å›¾è°±ç”Ÿæˆå™¨ - å¹¶è¡Œç‰ˆæœ¬"""
    
    def __init__(self, workers: int = 8):
        """åˆå§‹åŒ–"""
        self.client = OpenAI(
            api_key="sk-pBUBTdSpfx0ppYf30rzzmbr60WiffKq52EQzx45r9rntGjli",
            base_url="https://www.dmxapi.cn/v1",
        )
        self.model = "DMXAPI-DeepSeek-V3"
        self.workers = workers
        self.max_retries = 3
        
        # çº¿ç¨‹å®‰å…¨çš„ç»“æœå­˜å‚¨
        self.results_lock = threading.Lock()
        self.sub_domain_kgs = []
        self.failed_sections = []
        
        # è¿›åº¦è·Ÿè¸ª
        self.progress_tracker = None
        
        print("ğŸ”¬ [å­é€»è¾‘ç”Ÿæˆå™¨] åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“¡ ä½¿ç”¨æ¨¡å‹: {self.model}")
        print(f"ğŸš€ æœ€å¤§å¹¶å‘æ•°: {workers}")
        print(f"ğŸ”„ æœ€å¤§é‡è¯•æ¬¡æ•°: {self.max_retries}")
    
    def generate_sub_logic(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå­é€»è¾‘çŸ¥è¯†å›¾è°±"""
        print("\n" + "="*60)
        print("ğŸ”¬ å¼€å§‹å­é€»è¾‘å›¾è°±ç”Ÿæˆ")
        print("="*60)
        
        # 1. åŠ è½½ç« èŠ‚æ•°æ®
        sections_data = self._load_sections_data()
        if not sections_data:
            print("âŒ æ— æ³•åŠ è½½ç« èŠ‚æ•°æ®")
            return []
        
        # 2. å¹¶å‘æå–å­é€»è¾‘å›¾è°±
        sub_logic_kgs = self._extract_concurrent(sections_data['sections'])
        
        # 3. éªŒè¯å’Œä¼˜åŒ–
        validated_kgs = self._validate_sub_logic_kgs(sub_logic_kgs)
        
        # 4. ä¿å­˜ç»“æœ
        self._save_sub_logic_kgs(validated_kgs)
        
        print(f"âœ… å­é€»è¾‘å›¾è°±ç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(validated_kgs)} ä¸ªå›¾è°±")
        return validated_kgs
    
    def _load_sections_data(self) -> Dict[str, Any]:
        """åŠ è½½ç« èŠ‚æ•°æ®"""
        print("ğŸ“‚ åŠ è½½ç« èŠ‚æ•°æ®...")
        
        try:
            sections_file = file_manager.get_path("sections", "document_sections.json")
            with open(sections_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            sections = data.get('sections', [])
            print(f"âœ… æˆåŠŸåŠ è½½ {len(sections)} ä¸ªç« èŠ‚")
            
            # è¿‡æ»¤æ‰å†…å®¹å¤ªçŸ­çš„ç« èŠ‚
            filtered_sections = []
            for section in sections:
                if len(section.get('content', '')) > 200:  # è‡³å°‘200å­—ç¬¦
                    filtered_sections.append(section)
                else:
                    print(f"âš ï¸ è·³è¿‡å†…å®¹è¿‡çŸ­çš„ç« èŠ‚: {section['section_num']}")
            
            print(f"ğŸ“‹ è¿‡æ»¤åæœ‰æ•ˆç« èŠ‚: {len(filtered_sections)} ä¸ª")
            data['sections'] = filtered_sections
            return data
            
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return {}
    
    def _extract_concurrent(self, sections: List[Dict]) -> List[Dict]:
        """å¹¶å‘æå–å­é€»è¾‘å›¾è°±"""
        print(f"\nğŸš€ å¼€å§‹å¹¶å‘å¤„ç† {len(sections)} ä¸ªç« èŠ‚...")
        
        # åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ª
        self.progress_tracker = ProgressTracker(len(sections), "å­é€»è¾‘å›¾è°±æå–")
        
        results = []
        
        with ThreadPoolExecutor(max_workers=self.workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_section = {
                executor.submit(self.process_single_section, section): section
                for section in sections
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_section):
                section = future_to_section[future]
                try:
                    section_data, analysis_data, success = future.result()
                    
                    if success and analysis_data:
                        # æ„å»ºçŸ¥è¯†å›¾è°±æ ¼å¼
                        kg_data = self._build_kg_from_analysis(analysis_data, section_data['section_num'], section_data['title'])
                        if kg_data:
                            kg_data['section_num'] = section_data['section_num']
                            kg_data['title'] = section_data['title']
                            kg_data['extraction_timestamp'] = datetime.now().isoformat()
                            results.append(kg_data)
                    else:
                        with self.results_lock:
                            self.failed_sections.append(section_data['section_num'])
                    
                    # æ›´æ–°è¿›åº¦
                    self.progress_tracker.update()
                    
                except Exception as e:
                    print(f"âŒ å¤„ç†ç« èŠ‚ {section['section_num']} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    with self.results_lock:
                        self.failed_sections.append(section['section_num'])
                    self.progress_tracker.update()
        
        # è¿›åº¦å®Œæˆ
        
        print(f"\nğŸ“Š å¹¶å‘å¤„ç†å®Œæˆ:")
        print(f"   - æˆåŠŸç« èŠ‚: {len(results)} ä¸ª")
        print(f"   - å¤±è´¥ç« èŠ‚: {len(self.failed_sections)} ä¸ª")
        if self.failed_sections:
            print(f"   - å¤±è´¥åˆ—è¡¨: {', '.join(self.failed_sections)}")
        
        return results
    
    def process_single_section(self, section: Dict) -> Tuple[Dict, Dict, bool]:
        """å¤„ç†å•ä¸ªç« èŠ‚ï¼ˆç”¨äºå¹¶è¡Œæ‰§è¡Œï¼‰"""
        section_num = section['section_num']
        title = section['title']
        
        print(f"ğŸ” [çº¿ç¨‹-{threading.current_thread().name}] å¼€å§‹å¤„ç†ç« èŠ‚: {section_num}")
        
        # é‡è¯•æœºåˆ¶
        for attempt in range(self.max_retries):
            try:
                # åˆ†æç« èŠ‚
                analysis_data = self._call_deepseek_with_cot_triplet_extraction(section)
                
                if analysis_data:
                    print(f"âœ… [çº¿ç¨‹-{threading.current_thread().name}] ç« èŠ‚ {section_num} åˆ†ææˆåŠŸ")
                    return section, analysis_data, True
                else:
                    print(f"âš ï¸ [çº¿ç¨‹-{threading.current_thread().name}] ç« èŠ‚ {section_num} åˆ†æå¤±è´¥ï¼Œå°è¯• {attempt + 1}/{self.max_retries}")
                    
            except Exception as e:
                print(f"âŒ [çº¿ç¨‹-{threading.current_thread().name}] ç« èŠ‚ {section_num} å¤„ç†é”™è¯¯ (å°è¯• {attempt + 1}/{self.max_retries}): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(1)  # é‡è¯•å‰ç­‰å¾…1ç§’
        
        print(f"âŒ [çº¿ç¨‹-{threading.current_thread().name}] ç« èŠ‚ {section_num} æœ€ç»ˆå¤±è´¥")
        return section, {}, False
    
    def _call_deepseek_with_cot_triplet_extraction(self, section: Dict) -> Dict:
        """ä½¿ç”¨CoTæ–¹æ³•è°ƒç”¨DeepSeekè¿›è¡Œä¸‰å…ƒç»„çŸ¥è¯†æå–"""
        
        # å®‰å…¨çš„ç« èŠ‚å·å¤„ç†
        section_num_safe = re.sub(r'[^\w]', '_', str(section['section_num']))
        
        # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œé¿å…tokenè¿‡å¤š
        content = section['content']
        if len(content) > 16000:
            content = content[:16000] + "..."
        
        cot_prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç”µè·¯è®¾è®¡ä¸“å®¶å’ŒçŸ¥è¯†å·¥ç¨‹å¸ˆã€‚è¯·ä½¿ç”¨é€æ­¥æ€è€ƒçš„æ–¹æ³•ä»ä»¥ä¸‹ç”µè·¯æŠ€æœ¯ç« èŠ‚ä¸­æå–ä¸‰å…ƒç»„çŸ¥è¯†å›¾è°±ã€‚

## ç« èŠ‚ä¿¡æ¯
- **ç« èŠ‚å·**: {section['section_num']}
- **æ ‡é¢˜**: {section['title']}
- **å†…å®¹**: {content}

## åˆ†æä»»åŠ¡
è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œåˆ†æï¼š

### ç¬¬ä¸€æ­¥ï¼šå†…å®¹ç†è§£
ä»”ç»†é˜…è¯»ç« èŠ‚å†…å®¹ï¼Œç†è§£ä¸»è¦æŠ€æœ¯ä¸»é¢˜å’ŒçŸ¥è¯†ç»“æ„ã€‚

### ç¬¬äºŒæ­¥ï¼šçŸ¥è¯†åˆ†å±‚æå–
æŒ‰ç…§ä»¥ä¸‹ä¸‰ä¸ªå±‚æ¬¡æå–çŸ¥è¯†èŠ‚ç‚¹ï¼š

**1. åŸºç¡€æ¦‚å¿µå±‚ (Basic Concepts)**
- æå–ï¼šåŸºæœ¬å®šä¹‰ã€åŸç†ã€å®šå¾‹ã€å…¬å¼ã€å‚æ•°ç­‰
- ç‰¹å¾ï¼šç†è®ºæ€§å¼ºï¼Œæ˜¯å…¶ä»–çŸ¥è¯†çš„åŸºç¡€
- è¦æ±‚ï¼šæ¯ä¸ªæ¦‚å¿µéƒ½è¦æœ‰æ˜ç¡®çš„å®šä¹‰å’Œè§£é‡Š

**2. æ ¸å¿ƒæŠ€æœ¯å±‚ (Core Technologies)**
- æå–ï¼šå®ç°æ–¹æ³•ã€è®¾è®¡æŠ€å·§ã€åˆ†ææ–¹æ³•ã€ç®—æ³•ç­‰
- ç‰¹å¾ï¼šæ–¹æ³•æ€§å¼ºï¼Œè¿æ¥ç†è®ºä¸åº”ç”¨
- è¦æ±‚ï¼šæ¯ä¸ªæŠ€æœ¯éƒ½è¦æœ‰å…·ä½“çš„å®ç°æ­¥éª¤

**3. ç”µè·¯åº”ç”¨å±‚ (Circuit Applications)**
- æå–ï¼šå…·ä½“ç”µè·¯ã€è®¾è®¡å®ä¾‹ã€åº”ç”¨åœºæ™¯ç­‰
- ç‰¹å¾ï¼šå®è·µæ€§å¼ºï¼Œé¢å‘å…·ä½“åº”ç”¨
- è¦æ±‚ï¼šæ¯ä¸ªåº”ç”¨éƒ½è¦æœ‰å…·ä½“çš„ç”µè·¯ç»“æ„

### ç¬¬ä¸‰æ­¥ï¼šå…³ç³»è¯†åˆ«
è¯†åˆ«ä»¥ä¸‹ç±»å‹çš„çŸ¥è¯†å…³ç³»ï¼š

**å±‚é—´å…³ç³»**ï¼š
- enables: åŸºç¡€æ¦‚å¿µä½¿èƒ½æ ¸å¿ƒæŠ€æœ¯
- supports: åŸºç¡€æ¦‚å¿µæ”¯æ’‘æ ¸å¿ƒæŠ€æœ¯
- implements: æ ¸å¿ƒæŠ€æœ¯å®ç°ç”µè·¯åº”ç”¨
- applies_to: æ ¸å¿ƒæŠ€æœ¯åº”ç”¨äºç”µè·¯åº”ç”¨

**å±‚å†…å…³ç³»**ï¼š
- depends_on: ä¾èµ–å…³ç³»
- relates_to: ç›¸å…³å…³ç³»
- complements: äº’è¡¥å…³ç³»
- extends: æ‰©å±•å…³ç³»

### ç¬¬å››æ­¥ï¼šæ„å»ºçŸ¥è¯†å›¾è°±
åŸºäºä¸Šè¿°åˆ†æï¼Œæ„å»ºç»“æ„åŒ–çš„çŸ¥è¯†å›¾è°±ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š

```json
{{
  "section_analysis": {{
    "section_num": "{section['section_num']}",
    "title": "{section['title']}",
    "content_summary": "ç« èŠ‚å†…å®¹çš„ç®€è¦æ¦‚è¿°",
    "knowledge_density": "é«˜",
    "complexity_level": 3,
    "key_themes": ["ä¸»è¦æŠ€æœ¯ä¸»é¢˜1", "ä¸»è¦æŠ€æœ¯ä¸»é¢˜2"]
  }},
  "basic_concepts": [
    {{
      "id": "bc_{section_num_safe}_1",
      "label": "æ¦‚å¿µåç§°",
      "summary": "æ¦‚å¿µçš„è¯¦ç»†æè¿°ï¼ŒåŒ…æ‹¬å®šä¹‰ã€åŸç†ã€ç‰¹ç‚¹ç­‰",
      "difficulty": 2,
      "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
      "formulas": ["ç›¸å…³å…¬å¼"],
      "applications": ["åº”ç”¨åœºæ™¯"],
      "properties": {{
        "category": "å®šä¹‰",
        "mathematical_level": "åŸºç¡€",
        "prerequisite_knowledge": ["å‰ç½®çŸ¥è¯†"]
      }}
    }}
  ],
  "core_technologies": [
    {{
      "id": "ct_{section_num_safe}_1",
      "label": "æŠ€æœ¯åç§°",
      "summary": "æŠ€æœ¯çš„è¯¦ç»†æè¿°ï¼ŒåŒ…æ‹¬æ–¹æ³•ã€æ­¥éª¤ã€ä¼˜åŠ¿ç­‰",
      "difficulty": 3,
      "keywords": ["æŠ€æœ¯å…³é”®è¯1", "æŠ€æœ¯å…³é”®è¯2"],
      "formulas": ["ç›¸å…³ç®—æ³•å…¬å¼"],
      "applications": ["æŠ€æœ¯åº”ç”¨"],
      "properties": {{
        "category": "åˆ†ææ–¹æ³•",
        "implementation_complexity": "ä¸­ç­‰",
        "required_tools": ["å·¥å…·1"]
      }}
    }}
  ],
  "circuit_applications": [
    {{
      "id": "ca_{section_num_safe}_1",
      "label": "åº”ç”¨åç§°",
      "summary": "åº”ç”¨çš„è¯¦ç»†æè¿°ï¼ŒåŒ…æ‹¬ç”µè·¯ç»“æ„ã€åŠŸèƒ½ã€ç‰¹ç‚¹ç­‰",
      "difficulty": 4,
      "keywords": ["åº”ç”¨å…³é”®è¯1", "åº”ç”¨å…³é”®è¯2"],
      "formulas": ["è®¾è®¡å…¬å¼"],
      "applications": ["å…·ä½“åº”ç”¨åœºæ™¯"],
      "properties": {{
        "category": "ç”µè·¯æ‹“æ‰‘",
        "performance_metrics": ["æ€§èƒ½æŒ‡æ ‡"],
        "design_constraints": ["è®¾è®¡çº¦æŸ"]
      }}
    }}
  ],
  "relationships": [
    {{
      "source_id": "bc_{section_num_safe}_1",
      "target_id": "ct_{section_num_safe}_1",
      "relationship": "enables",
      "description": "è¯¦ç»†æè¿°è¿™ç§å…³ç³»",
      "weight": 0.8,
      "evidence": "æ”¯æ’‘è¿™ç§å…³ç³»çš„æ–‡æœ¬è¯æ®",
      "bidirectional": false
    }}
  ]
}}
```

è¦æ±‚ï¼š
1. åŸºç¡€æ¦‚å¿µã€æ ¸å¿ƒæŠ€æœ¯ã€ç”µè·¯åº”ç”¨ä¸ªæ•°ä¸é™åˆ¶
2. æ¯ä¸ªèŠ‚ç‚¹çš„summaryè¦è¯¦ç»†ä¸”å‡†ç¡®
3. å…³ç³»è¦çœŸå®å­˜åœ¨ï¼Œä¸èƒ½æœæ’°
4. æ‰€æœ‰å­—æ®µéƒ½è¦å¡«å†™ï¼Œä¸èƒ½ä¸ºç©º
5. JSONæ ¼å¼è¦ä¸¥æ ¼æ­£ç¡®

å¼€å§‹åˆ†æï¼š"""
        
        try:
            response = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯é¡¶çº§çš„ç”µè·¯è®¾è®¡ä¸“å®¶å’ŒçŸ¥è¯†å·¥ç¨‹å¸ˆã€‚ä½ æ“…é•¿ä»æŠ€æœ¯æ–‡æ¡£ä¸­æå–ç»“æ„åŒ–çš„ä¸‰å…ƒç»„çŸ¥è¯†å›¾è°±ï¼Œèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«çŸ¥è¯†çš„å±‚æ¬¡ç»“æ„å’Œç›¸äº’å…³ç³»ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¿›è¡Œæ·±å…¥åˆ†æï¼Œç¡®ä¿æå–çš„çŸ¥è¯†å‡†ç¡®ã€å®Œæ•´ã€æœ‰ç”¨ã€‚"},
                    {"role": "user", "content": cot_prompt}
                ],
                model=self.model,
                temperature=0.1,
                max_tokens=8000
            )
            
            result_content = response.choices[0].message.content.strip()
            
            # è§£æJSONç»“æœ - ä½¿ç”¨æ›´å®Œå–„çš„æ¸…ç†æ–¹æ³•
            json_str = self._clean_json_response(result_content)
            kg_data = json.loads(json_str)
            
            return kg_data
            
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {result_content[:500]}...")
            # é™çº§åˆ°è§„åˆ™æå–
            return self._rule_based_extraction(section['section_num'], section['title'], section['content'])
            
        except Exception as e:
            print(f"AIæå–å¤±è´¥: {e}")
            # é™çº§åˆ°è§„åˆ™æå–
            return self._rule_based_extraction(section['section_num'], section['title'], section['content'])
    
    def _clean_json_response(self, content: str) -> str:
        """æ¸…ç†JSONå“åº” - å‚è€ƒæ‚¨çš„æˆåŠŸä»£ç """
        # ç§»é™¤markdownä»£ç å—æ ‡è®°
        content = re.sub(r'```json\s*', '', content)
        content = re.sub(r'```\s*$', '', content)
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        content = content.strip()
        
        # å°è¯•æ‰¾åˆ°JSONå¯¹è±¡çš„å¼€å§‹å’Œç»“æŸ
        start_idx = content.find('{')
        end_idx = content.rfind('}')
        
        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            content = content[start_idx:end_idx+1]
        
        return content

    def _build_kg_from_analysis(self, analysis_data: Dict[str, Any], section_num: str, title: str) -> Dict[str, Any]:
        """ä»åˆ†ææ•°æ®æ„å»ºçŸ¥è¯†å›¾è°±æ ¼å¼"""
        try:
            nodes = []
            edges = []

            # å¤„ç†åŸºç¡€æ¦‚å¿µ
            for concept in analysis_data.get('basic_concepts', []):
                node = {
                    'id': concept.get('id', ''),
                    'label': concept.get('label', ''),
                    'node_type': 'basic_concept',
                    'summary': concept.get('summary', ''),
                    'difficulty': concept.get('difficulty', 2),
                    'keywords': concept.get('keywords', []),
                    'formulas': concept.get('formulas', []),
                    'applications': concept.get('applications', []),
                    'related_sections': [],
                    'prerequisites': concept.get('properties', {}).get('prerequisite_knowledge', []),
                    'derived_concepts': [],
                    'practical_examples': [],
                    'technical_details': concept.get('summary', '')[:200]
                }
                nodes.append(node)

            # å¤„ç†æ ¸å¿ƒæŠ€æœ¯
            for tech in analysis_data.get('core_technologies', []):
                node = {
                    'id': tech.get('id', ''),
                    'label': tech.get('label', ''),
                    'node_type': 'core_technology',
                    'summary': tech.get('summary', ''),
                    'difficulty': tech.get('difficulty', 3),
                    'keywords': tech.get('keywords', []),
                    'formulas': tech.get('formulas', []),
                    'applications': tech.get('applications', []),
                    'related_sections': [],
                    'prerequisites': [],
                    'derived_concepts': [],
                    'practical_examples': [],
                    'technical_details': tech.get('summary', '')[:200]
                }
                nodes.append(node)

            # å¤„ç†ç”µè·¯åº”ç”¨
            for app in analysis_data.get('circuit_applications', []):
                node = {
                    'id': app.get('id', ''),
                    'label': app.get('label', ''),
                    'node_type': 'circuit_application',
                    'summary': app.get('summary', ''),
                    'difficulty': app.get('difficulty', 4),
                    'keywords': app.get('keywords', []),
                    'formulas': app.get('formulas', []),
                    'applications': app.get('applications', []),
                    'related_sections': [],
                    'prerequisites': [],
                    'derived_concepts': [],
                    'practical_examples': [],
                    'technical_details': app.get('summary', '')[:200]
                }
                nodes.append(node)

            # å¤„ç†å…³ç³»
            for rel in analysis_data.get('relationships', []):
                edge = {
                    'source_id': rel.get('source_id', ''),
                    'target_id': rel.get('target_id', ''),
                    'relationship': rel.get('relationship', 'relates_to'),
                    'description': rel.get('description', ''),
                    'weight': rel.get('weight', 0.5),
                    'evidence': rel.get('evidence', ''),
                    'bidirectional': rel.get('bidirectional', False)
                }
                edges.append(edge)

            return {
                'nodes': nodes,
                'edges': edges
            }

        except Exception as e:
            print(f"æ„å»ºçŸ¥è¯†å›¾è°±å¤±è´¥: {e}")
            return {}

    def _rule_based_extraction(self, section_num: str, title: str, content: str) -> Dict[str, Any]:
        """è§„åˆ™æå–é™çº§æ–¹æ¡ˆ"""
        print(f"âš ï¸ ä½¿ç”¨è§„åˆ™æå–ä½œä¸ºé™çº§æ–¹æ¡ˆ: {section_num}")

        # ç®€å•çš„æ®µè½åˆ†å‰²
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]

        # æ”¹è¿›çš„å…³é”®è¯æå– - æ›´å‡†ç¡®åœ°è¯†åˆ«ç”µè·¯åº”ç”¨
        circuit_terms = {
            'basic_concept': ['å®šä¹‰', 'åŸç†', 'å®šå¾‹', 'å…¬å¼', 'æ¦‚å¿µ', 'ç†è®º', 'åŸºç¡€'],
            'core_technology': ['æ–¹æ³•', 'æŠ€æœ¯', 'ç®—æ³•', 'åˆ†æ', 'è®¾è®¡æŠ€å·§', 'å®ç°æ–¹æ³•'],
            'circuit_application': ['ç”µè·¯', 'æ”¾å¤§å™¨', 'æ»¤æ³¢å™¨', 'æŒ¯è¡å™¨', 'æ¯”è¾ƒå™¨', 'å¼€å…³', 'å˜æ¢å™¨', 'åº”ç”¨', 'å®ä¾‹', 'è®¾è®¡'],
            'design_method': ['æµç¨‹', 'æ­¥éª¤', 'å‡†åˆ™', 'ä¼˜åŒ–', 'è®¾è®¡æ–¹æ³•'],
            'analysis_tool': ['ä»¿çœŸ', 'æµ‹è¯•', 'å·¥å…·', 'è½¯ä»¶', 'SPICE', 'Matlab']
        }

        nodes = []
        node_id = 1

        for i, para in enumerate(paragraphs[:10]):  # æœ€å¤šå¤„ç†10ä¸ªæ®µè½
            if len(para) < 50:  # è·³è¿‡å¤ªçŸ­çš„æ®µè½
                continue

            # ç¡®å®šèŠ‚ç‚¹ç±»å‹ - æ”¹è¿›çš„åˆ†ç±»é€»è¾‘
            node_type = 'basic_concept'  # é»˜è®¤ç±»å‹
            type_scores = {}

            # è®¡ç®—æ¯ç§ç±»å‹çš„åŒ¹é…åˆ†æ•°
            for type_name, keywords in circuit_terms.items():
                score = sum(1 for keyword in keywords if keyword in para.lower())
                type_scores[type_name] = score

            # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç±»å‹
            if type_scores:
                node_type = max(type_scores, key=type_scores.get)
                # å¦‚æœæ²¡æœ‰æ˜æ˜¾åŒ¹é…ï¼Œä¿æŒé»˜è®¤
                if type_scores[node_type] == 0:
                    node_type = 'basic_concept'

            # æå–æ ‡é¢˜ï¼ˆæ®µè½çš„ç¬¬ä¸€å¥ï¼‰
            sentences = para.split('ã€‚')
            label = sentences[0][:50] + "..." if len(sentences[0]) > 50 else sentences[0]

            node = {
                'id': f"{section_num}_{node_type}_{node_id}",
                'label': label,
                'node_type': node_type,
                'summary': para[:300] + "..." if len(para) > 300 else para,
                'difficulty': 3,
                'keywords': [],
                'formulas': [],
                'applications': [],
                'related_sections': [section_num],
                'prerequisites': [],
                'derived_concepts': [],
                'practical_examples': [],
                'technical_details': para[:200]
            }

            nodes.append(node)
            node_id += 1

        return {
            'basic_concepts': [n for n in nodes if n['node_type'] == 'basic_concept'],
            'core_technologies': [n for n in nodes if n['node_type'] == 'core_technology'],
            'circuit_applications': [n for n in nodes if n['node_type'] == 'circuit_application'],
            'relationships': []
        }

    def _validate_sub_logic_kgs(self, sub_logic_kgs: List[Dict]) -> List[Dict]:
        """éªŒè¯å’Œä¼˜åŒ–å­é€»è¾‘å›¾è°±"""
        print(f"\nğŸ” éªŒè¯å’Œä¼˜åŒ– {len(sub_logic_kgs)} ä¸ªå­é€»è¾‘å›¾è°±...")

        validated_kgs = []

        for kg in sub_logic_kgs:
            if self._is_valid_kg(kg):
                validated_kgs.append(kg)
            else:
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆçš„çŸ¥è¯†å›¾è°±: {kg.get('section_num', 'Unknown')}")

        print(f"âœ… éªŒè¯å®Œæˆï¼Œæœ‰æ•ˆå›¾è°±: {len(validated_kgs)} ä¸ª")
        return validated_kgs

    def _is_valid_kg(self, kg: Dict) -> bool:
        """æ£€æŸ¥çŸ¥è¯†å›¾è°±æ˜¯å¦æœ‰æ•ˆ"""
        if not kg.get('nodes'):
            return False

        # æ£€æŸ¥èŠ‚ç‚¹æ•°é‡
        if len(kg['nodes']) < 2:
            return False

        # æ£€æŸ¥èŠ‚ç‚¹å®Œæ•´æ€§
        for node in kg['nodes']:
            if not node.get('id') or not node.get('label'):
                return False

        return True

    def _save_sub_logic_kgs(self, sub_logic_kgs: List[Dict]):
        """ä¿å­˜å­é€»è¾‘å›¾è°±"""
        print("ğŸ’¾ ä¿å­˜å­é€»è¾‘å›¾è°±...")

        # ä¿å­˜æ±‡æ€»æ•°æ®
        summary_data = {
            'title': 'å­é€»è¾‘çŸ¥è¯†å›¾è°±æ±‡æ€»',
            'timestamp': datetime.now().isoformat(),
            'total_kgs': len(sub_logic_kgs),
            'total_nodes': sum(len(kg.get('nodes', [])) for kg in sub_logic_kgs),
            'total_edges': sum(len(kg.get('edges', [])) for kg in sub_logic_kgs),
            'sub_logic_kgs': sub_logic_kgs
        }

        file_manager.save_json(summary_data, "sub_logic", "sub_logic_summary.json")

        # ä¿å­˜æ¯ä¸ªå›¾è°±çš„å•ç‹¬æ–‡ä»¶
        for kg in sub_logic_kgs:
            section_num = kg.get('section_num', 'unknown')
            filename = f"sub_logic_{section_num.replace('.', '_')}.json"
            file_manager.save_json(kg, "sub_logic", filename)

        print(f"âœ… å­é€»è¾‘å›¾è°±ä¿å­˜å®Œæˆ")
        print(f"   - æ€»å›¾è°±æ•°: {len(sub_logic_kgs)}")
        print(f"   - æ€»èŠ‚ç‚¹æ•°: {sum(len(kg.get('nodes', [])) for kg in sub_logic_kgs)}")
        print(f"   - æ€»è¾¹æ•°: {sum(len(kg.get('edges', [])) for kg in sub_logic_kgs)}")

def main():
    """æµ‹è¯•å‡½æ•°"""
    generator = SubLogicGenerator(workers=8)

    # ç”Ÿæˆå­é€»è¾‘å›¾è°±
    result = generator.generate_sub_logic()

    if result:
        print(f"ç”ŸæˆæˆåŠŸ: {len(result)} ä¸ªå­é€»è¾‘å›¾è°±")
    else:
        print("ç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    main()
